# Parler-TTS ë²¡í„° ê¸°ë°˜ íš¨ìœ¨ì  ìŒì„± í•©ì„± ì‹œìŠ¤í…œ
## í”„ë¡œì íŠ¸ ì½”ë“œ ë¶„ì„ ë° êµ¬í˜„ ì„¤ëª…

---

## ğŸ“‹ ëª©ì°¨
1. [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)
2. [í•µì‹¬ ì•„í‚¤í…ì²˜](#í•µì‹¬-ì•„í‚¤í…ì²˜)
3. [ì£¼ìš” ëª¨ë“ˆ ë¶„ì„](#ì£¼ìš”-ëª¨ë“ˆ-ë¶„ì„)
4. [ë²¡í„° ê¸°ë°˜ ì ‘ê·¼ë²•](#ë²¡í„°-ê¸°ë°˜-ì ‘ê·¼ë²•)
5. [PEFT ëª¨ë“ˆ ì‹œìŠ¤í…œ](#peft-ëª¨ë“ˆ-ì‹œìŠ¤í…œ)
6. [í›ˆë ¨ íŒŒì´í”„ë¼ì¸](#í›ˆë ¨-íŒŒì´í”„ë¼ì¸)
7. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
8. [ê²°ë¡  ë° ì˜ì˜](#ê²°ë¡ -ë°-ì˜ì˜)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

### ê¸°ë³¸ ê°œë…
- **Parler-TTS**: í…ìŠ¤íŠ¸ ì„¤ëª…ì„ í†µí•´ ì œì–´ ê°€ëŠ¥í•œ ìŒì„± í•©ì„± ëª¨ë¸
- **ëª©í‘œ**: T5 ì¸ì½”ë”ë¥¼ ì‚¬ì „ ê³„ì‚°ëœ ë²¡í„°ë¡œ ëŒ€ì²´í•˜ì—¬ ì¶”ë¡  íš¨ìœ¨ì„± ê·¹ëŒ€í™”
- **í•µì‹¬ í˜ì‹ **: PEFT(Parameter-Efficient Fine-Tuning)ë¥¼ í†µí•œ ë²¡í„° ê¸°ë°˜ ìŠ¤íƒ€ì¼ ì œì–´

### ê¸°ì¡´ ë°©ì‹ vs ìƒˆë¡œìš´ ë°©ì‹
```
[ê¸°ì¡´] í…ìŠ¤íŠ¸ ì„¤ëª… â†’ T5 ì¸ì½”ë” â†’ í¬ë¡œìŠ¤ ì–´í…ì…˜ â†’ ë””ì½”ë” â†’ ì˜¤ë””ì˜¤
[ìƒˆë¡œìš´] ì‚¬ì „ê³„ì‚° ë²¡í„° â†’ PEFT ëª¨ë“ˆ â†’ í¬ë¡œìŠ¤ ì–´í…ì…˜ â†’ ë””ì½”ë” â†’ ì˜¤ë””ì˜¤
```

---

## ğŸ—ï¸ í•µì‹¬ ì•„í‚¤í…ì²˜

### ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ
1. **í…ìŠ¤íŠ¸ ì¸ì½”ë”**: Frozen Flan-T5 (ì›ë˜ ë°©ì‹) â†’ ì‚¬ì „ê³„ì‚° ë²¡í„° (ìƒˆë¡œìš´ ë°©ì‹)
2. **Parler-TTS ë””ì½”ë”**: ì˜¤ë””ì˜¤ í† í° ìƒì„±ì„ ìœ„í•œ ì–¸ì–´ ëª¨ë¸
3. **ì˜¤ë””ì˜¤ ì½”ë±**: DAC ëª¨ë¸ë¡œ í† í°ì„ íŒŒí˜•ìœ¼ë¡œ ë³€í™˜

### ë²¡í„° ê¸°ë°˜ ì•„í‚¤í…ì²˜ í˜ì‹ 
```python
# parler_tts/configuration_parler_tts.py:260-314
use_precomputed_vectors=False,
precomputed_vector_dim=1024,
num_precomputed_vectors=64,
attribute_vector_indices=None,
lora_rank=16,
lora_alpha=32.0,
vae_latent_dim=128,
orthogonal_reg_strength=0.01,
```

---

## ğŸ“ ì£¼ìš” ëª¨ë“ˆ ë¶„ì„

### 1. ëª¨ë¸ êµ¬ì„± (Configuration)

#### `ParlerTTSConfig` í´ë˜ìŠ¤
- **ìœ„ì¹˜**: `parler_tts/configuration_parler_tts.py:175-346`
- **ì—­í• **: ëª¨ë¸ì˜ ëª¨ë“  ì„¤ì • ë§¤ê°œë³€ìˆ˜ ê´€ë¦¬
- **í•µì‹¬ íŠ¹ì§•**:
  - ë²¡í„° ê¸°ë°˜ ëª¨ë“œ ì„¤ì • (`use_precomputed_vectors`)
  - PEFT íŒŒë¼ë¯¸í„° ê´€ë¦¬ (LoRA rank, VAE latent dim)
  - ì†ì„±ë³„ ë²¡í„° ì¸ë±ìŠ¤ ê´€ë¦¬

```python
# 6ê°€ì§€ ìŒì„± ì†ì„± ì •ì˜
attribute_values = {
    "gender": ["male", "female"],
    "pitch": ["high", "low", "medium"], 
    "speed": ["slowly", "quickly", "moderate"],
    "accent": ["American", "British", "Chinese", ...], # 40+ ì–µì–‘
    "modulation": ["monoton", "animated"],
    "quality": ["clean", "noisy"]
}
```

### 2. ë²¡í„° ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ

#### `VectorLoader` í´ë˜ìŠ¤
- **ìœ„ì¹˜**: `parler_tts/vector_utils.py:8-162`
- **í•µì‹¬ ê¸°ëŠ¥**:
  - ìŠ¤íƒ€ì¼ ìº¡ì…˜ì„ í† í°ìœ¼ë¡œ íŒŒì‹±
  - ì†ì„±ë³„/ë¹„ì†ì„±ë³„ ë²¡í„° ë¡œë”©
  - ì‹œí€€ìŠ¤ ì—°ê²° ë° ì¸ë±ìŠ¤ ë§¤í•‘

```python
class VectorLoader:
    def get_vectors_for_caption(self, caption: str):
        """
        "female American quickly" â†’ 
        - vectors: (seq_len, 1024) í…ì„œ
        - tokens: ['female', 'american', 'quickly', '<_s>'] 
        - attributes: {'gender': 'female', 'accent': 'American', 'speed': 'quickly'}
        """
```

### 3. ëª¨ë¸ë§ í•µì‹¬

#### `ParlerTTSForConditionalGeneration`
- **ìœ„ì¹˜**: `parler_tts/modeling_parler_tts.py`
- **ë²¡í„° ì²˜ë¦¬ ë¡œì§**:
  - T5 ì¸ì½”ë” ìš°íšŒ
  - ì‚¬ì „ê³„ì‚° ë²¡í„° ì§ì ‘ í¬ë¡œìŠ¤ ì–´í…ì…˜ ê³µê¸‰
  - PEFT ëª¨ë“ˆê³¼ í†µí•©

---

## ğŸ§  ë²¡í„° ê¸°ë°˜ ì ‘ê·¼ë²•

### ë²¡í„° ì¡°ì§ êµ¬ì¡°
```
vectors/
â”œâ”€â”€ gender/
â”‚   â”œâ”€â”€ male.pt
â”‚   â””â”€â”€ female.pt
â”œâ”€â”€ accent/
â”‚   â”œâ”€â”€ American.pt
â”‚   â”œâ”€â”€ British.pt
â”‚   â””â”€â”€ ... (40+ files)
â”œâ”€â”€ pitch/
â”‚   â”œâ”€â”€ high.pt
â”‚   â”œâ”€â”€ medium.pt
â”‚   â””â”€â”€ low.pt
â””â”€â”€ nonattr_tokens/
    â”œâ”€â”€ voice.pt
    â”œâ”€â”€ with.pt
    â””â”€â”€ ... (ê¸°íƒ€ í† í°ë“¤)
```

### ìŠ¤ë§ˆíŠ¸ í† í° ì²˜ë¦¬
```python
def parse_style_caption(self, caption: str):
    # T5 í† í¬ë‚˜ì´ì €ë¡œ ì„œë¸Œì›Œë“œ ë¶„í• 
    tokens = self.tokenizer.convert_ids_to_tokens(tokenized['input_ids'])
    
    # ë§ˆì¹¨í‘œ ìŠ¤ë§ˆíŠ¸ ì²˜ë¦¬
    cleaned_tokens = tokens + ['<_s>']  # ì¢…ë£Œ í† í° ìë™ ì¶”ê°€
    
    # ì†ì„± í† í° ì‹ë³„
    attributes = {}
    for token in cleaned_tokens[:-1]:
        clean_token = token.replace('â–', '').lower().strip()
        if clean_token in self.token_to_attribute:
            attr_type, attr_value = self.token_to_attribute[clean_token]
            attributes[attr_type] = attr_value
```

---

## âš™ï¸ PEFT ëª¨ë“ˆ ì‹œìŠ¤í…œ

### 1. LoRA (Low-Rank Adaptation)

#### `LoRAVectorTransform` í´ë˜ìŠ¤
- **ìœ„ì¹˜**: `parler_tts/peft_modules.py:15-66`
- **ì›ë¦¬**: `W = Wâ‚€ + (B @ A) * scaling`
- **íŠ¹ì§•**: 
  - 1024ì°¨ì› ë²¡í„°ë¥¼ rank 16ìœ¼ë¡œ ë¶„í•´
  - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸

```python
class LoRAVectorTransform(nn.Module):
    def __init__(self, vector_dim=1024, rank=16, alpha=32.0):
        self.lora_A = nn.Parameter(torch.randn(vector_dim, rank) * 0.01)
        self.lora_B = nn.Parameter(torch.zeros(rank, vector_dim))
        self.scaling = alpha / rank
    
    def forward(self, x):
        # LoRA ë³€í™˜: x + (x @ A @ B) * scaling
        temp = torch.matmul(x, self.lora_A)
        lora_output = torch.matmul(temp, self.lora_B) * self.scaling
        return x + self.dropout(lora_output)
```

### 2. VAE (Variational Autoencoder)

#### `AttributeVAE` í´ë˜ìŠ¤
- **ìœ„ì¹˜**: `parler_tts/peft_modules.py:68-152`  
- **ëª©ì **: ì†ì„±ë³„ ë²¡í„°ì˜ í‰ê· /ë¶„ì‚° í•™ìŠµ
- **ì•„í‚¤í…ì²˜**: ë‹¨ì¼ ë ˆì´ì–´ ì¸ì½”ë”/ë””ì½”ë”ë¡œ ë‹¨ìˆœí™”

```python
class AttributeVAE(nn.Module):
    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        vae_output = self.decode(z)
        enhanced_x = x + vae_output  # ì”ì°¨ ì—°ê²°
        return enhanced_x, mu, logvar
```

### 3. ì§êµì„± ì •ê·œí™”

#### `OrthogonalityRegularizer`
- **ìœ„ì¹˜**: `parler_tts/peft_modules.py:154-194`
- **ëª©ì **: í–¥ìƒëœ ë²¡í„°ë“¤ì´ ì„œë¡œ êµ¬ë³„ë˜ë„ë¡ ìœ ì§€
- **ë°©ë²•**: ê·¸ëŒ í–‰ë ¬ì˜ ë¹„ëŒ€ê° ìš”ì†Œ í˜ë„í‹°

### 4. í†µí•© PEFT ì‹œìŠ¤í…œ

#### `PrecomputedVectorPEFT` í´ë˜ìŠ¤
- **ìœ„ì¹˜**: `parler_tts/peft_modules.py:253-410`
- **í•µì‹¬ íŠ¹ì§•**:
  - **í† í° ë‚´ìš© ê¸°ë°˜ LoRA**: ê°™ì€ í† í°ì€ ìœ„ì¹˜ì™€ ìƒê´€ì—†ì´ ë™ì¼í•œ LoRA ì‚¬ìš©
  - **ë™ì  LoRA ìƒì„±**: ìƒˆë¡œìš´ ë¹„ì†ì„± í† í°ì— ëŒ€í•´ ìë™ìœ¼ë¡œ LoRA ì–´ëŒ‘í„° ìƒì„±
  - **ì†ì„±ë³„ VAE**: ê° ì†ì„± ê°’ë§ˆë‹¤ ì „ìš© VAE ëª¨ë“ˆ

```python
def forward(self, precomputed_vectors, description_tokens):
    for i, token in enumerate(description_tokens):
        if token in attribute_tokens:
            # ì†ì„± í† í° â†’ VAE ì²˜ë¦¬
            vae_module = self.vae_modules[attribute_key]
            enhanced_vector, mu, logvar = vae_module(vector)
        else:
            # ë¹„ì†ì„± í† í° â†’ LoRA ì²˜ë¦¬  
            lora_adapter = self.get_or_create_lora_adapter(token)
            enhanced_vector = lora_adapter(vector)
```

---

## ğŸš€ í›ˆë ¨ íŒŒì´í”„ë¼ì¸

### 1. ë°ì´í„° ì²˜ë¦¬

#### `DataCollatorParlerTTSWithVectors`
- **ìœ„ì¹˜**: `training/data.py:120-225`
- **í•µì‹¬ ê¸°ëŠ¥**:
  - ìŠ¤íƒ€ì¼ ìº¡ì…˜ì„ ë²¡í„°ë¡œ ë³€í™˜
  - ì†ì„± ì¸ë±ìŠ¤ ë°°ì¹˜ ìƒì„±
  - ë™ì  íŒ¨ë”© ë° ì–´í…ì…˜ ë§ˆìŠ¤í¬ ìƒì„±

```python
def __call__(self, features):
    description_vectors = []
    attribute_indices_batch = []
    
    for feature in features:
        style_caption = feature.get("rebuilt_caption", "")
        vectors, tokens, attributes = self.vector_loader.get_vectors_for_caption(style_caption)
        description_vectors.append(vectors)
        
        # PEFT ì ìš©ì„ ìœ„í•œ ì¸ë±ìŠ¤ ìƒì„±
        indices = self.vector_loader.get_attribute_indices(tokens)
        attribute_indices_batch.append(indices)
```

### 2. ë©”ì¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸

#### `run_parler_tts_vector_training.py`
- **ìœ„ì¹˜**: `training/run_parler_tts_vector_training.py`
- **ì£¼ìš” íŠ¹ì§•**:
  - **ì¡°ê±´ë¶€ ì²˜ë¦¬**: `use_precomputed_vectors` í”Œë˜ê·¸ë¡œ ë²¡í„°/í…ìŠ¤íŠ¸ ëª¨ë“œ ì „í™˜
  - **PEFT ì†ì‹¤ í†µí•©**: VAE KL loss + ì§êµì„± loss + ì¬êµ¬ì„± loss
  - **ë™ì  ë°°ì¹˜ ì²˜ë¦¬**: ì‹œí€€ìŠ¤ ê¸¸ì´ ì œí•œ ì—†ì´ ì²˜ë¦¬

```python
def train_step(batch):
    outputs = model(
        **batch, 
        loss_reduction="sum",
        vae_loss_weight=model_args.vae_loss_weight,          # VAE ì†ì‹¤ ê°€ì¤‘ì¹˜
        orthogonality_loss_weight=model_args.orthogonality_loss_weight  # ì§êµì„± ì†ì‹¤ ê°€ì¤‘ì¹˜
    )
    
    # í†µí•© ì†ì‹¤ ê³„ì‚°
    ce_loss = outputs.loss  # ì¬êµ¬ì„± ì†ì‹¤
    total_loss = ce_loss + vae_loss + orthogonal_loss
```

### 3. ë²¡í„° ë¡œë” í†µí•©
```python
# ë²¡í„° ë¡œë” ì´ˆê¸°í™”
if model_args.use_precomputed_vectors:
    vector_loader = VectorLoader(vector_base_path=model_args.vector_base_path)
    
    # ë²¡í„°ìš© ë°ì´í„° ì½œë ˆì´í„° ì‚¬ìš©
    data_collator = DataCollatorParlerTTSWithVectors(
        prompt_tokenizer=prompt_tokenizer,
        vector_loader=vector_loader,
        rebuilt_caption_column_name=data_args.rebuilt_caption_column_name
    )
```

---

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. íš¨ìœ¨ì„± í–¥ìƒ
- **T5 ì¸ì½”ë”© ìƒëµ**: ì¶”ë¡  ì‹œ í…ìŠ¤íŠ¸ ì¸ì½”ë” ìš°íšŒ
- **ì¦‰ì‹œ ë¡œë”©**: ì‚¬ì „ê³„ì‚° ë²¡í„°ë¥¼ ë°€ë¦¬ì´ˆ ë‹¨ìœ„ë¡œ ë¡œë“œ
- **ë©”ëª¨ë¦¬ íš¨ìœ¨**: ì¶”ë¡  ì¤‘ T5 ì¸ì½”ë” ë©”ëª¨ë¦¬ ë¶ˆí•„ìš”
- **ê²°ì •ë¡ ì **: ë™ì¼í•œ ìŠ¤íƒ€ì¼ ì„¤ëª…ì— ëŒ€í•´ í•­ìƒ ë™ì¼í•œ ë²¡í„°

### 2. í–¥ìƒëœ ì œì–´ì„±
- **ì§ì ‘ ì¡°ì‘**: ê°œë³„ ì†ì„± ë²¡í„°ë¥¼ ì§ì ‘ í¸ì§‘ ê°€ëŠ¥
- **ë¯¹ìŠ¤ ì•¤ ë§¤ì¹˜**: ì„œë¡œ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ ì„¤ëª…ì˜ ì†ì„± ê²°í•©
- **í•´ì„ ê°€ëŠ¥**: ì†ì„±ê³¼ ë²¡í„° ìœ„ì¹˜ ê°„ ëª…í™•í•œ ë§¤í•‘
- **PEFT ì¤€ë¹„**: ì„¸ë°€í•œ ìŠ¤íƒ€ì¼ ì ì‘ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬

### 3. ê²€ì¦ ê²°ê³¼
- **ë²¡í„° ì²˜ë¦¬ ê²€ì¦**: ìŠ¤íƒ€ì¼ ìº¡ì…˜ì´ í† í°ê³¼ ì†ì„±ìœ¼ë¡œ ì˜¬ë°”ë¥´ê²Œ íŒŒì‹±
- **ëª¨ë¸ í†µí•© í…ŒìŠ¤íŠ¸**: ë™ì  ì‹œí€€ìŠ¤ ê¸¸ì´ë¡œ ë²¡í„° ê¸°ë°˜ ì¶”ë¡  ì‘ë™
- **ì¶œë ¥ ì¼ê´€ì„±**: ì›ë³¸ T5 ì¸ì½”ë”ì™€ 98%+ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
- **PEFT í›ˆë ¨ ê²€ì¦**: í†µí•©ëœ VAE + LoRA + ì§êµì„± ì†ì‹¤ë¡œ í›ˆë ¨ ìˆ˜ë ´

---

## ğŸ¯ ì‚¬ìš© ì˜ˆì‹œ

### ê¸°ë³¸ ë²¡í„° ê¸°ë°˜ ì¶”ë¡ 
```python
from parler_tts import ParlerTTSForConditionalGeneration
from parler_tts.vector_utils import VectorLoader

# ëª¨ë¸ ë° ë²¡í„° ë¡œë” ì„¤ì •
model = ParlerTTSForConditionalGeneration.from_pretrained("parler-tts/parler-tts-mini-v1")
vector_loader = VectorLoader("/path/to/parler-tts")

# ì…ë ¥ ì¤€ë¹„
style_caption = "female American quickly medium clean"
text_prompt = "Hello world"

vectors, tokens, attributes = vector_loader.get_vectors_for_caption(style_caption)
prompt_ids = tokenizer(text_prompt, return_tensors="pt").input_ids

# ë²¡í„° ëª¨ë“œ ì„¤ì •
model.config.use_precomputed_vectors = True
model.config.precomputed_vector_dim = 1024

# ìƒì„±
generation = model.generate(
    prompt_input_ids=prompt_ids,
    precomputed_vectors=vectors.unsqueeze(0),
    attention_mask=torch.ones((1, vectors.shape[0])),
    max_new_tokens=1000
)
```

### í›ˆë ¨ ëª…ë ¹ì–´
```bash
# ë¹ ë¥¸ PEFT í…ŒìŠ¤íŠ¸ (CPU/ì†Œê·œëª¨)
uv run run_peft_training.py

# í”„ë¡œë•ì…˜ í›ˆë ¨ (GPU/ì „ì²´ ê·œëª¨)
accelerate launch training/run_parler_tts_vector_training.py \
    helpers/training_configs/vector_training_voxceleb.json
```

---

## ğŸ“ˆ ê²°ë¡  ë° ì˜ì˜

### ê¸°ìˆ ì  í˜ì‹ 
1. **íš¨ìœ¨ì„±**: T5 ì¸ì½”ë” ìƒëµìœ¼ë¡œ ì¶”ë¡  ì†ë„ ëŒ€í­ í–¥ìƒ
2. **í™•ì¥ì„±**: ë™ì  ë²¡í„° ì²˜ë¦¬ë¡œ ì‹œí€€ìŠ¤ ê¸¸ì´ ì œí•œ ì—†ìŒ
3. **ì œì–´ì„±**: ì†ì„±ë³„ ì„¸ë°€í•œ ìŒì„± ìŠ¤íƒ€ì¼ ì œì–´
4. **ì•ˆì •ì„±**: ì”ì°¨ ì—°ê²°ê³¼ ì •ê·œí™”ë¡œ í›ˆë ¨ ì•ˆì •ì„± í™•ë³´

### ì‹¤ìš©ì  ê°€ì¹˜
1. **ì‹¤ì‹œê°„ ì‘ìš©**: ì¶”ë¡  ìµœì í™”ë¡œ ì‹¤ì‹œê°„ TTS ê°€ëŠ¥
2. **ê°œì¸í™”**: PEFTë¥¼ í†µí•œ ì‚¬ìš©ìë³„ ìŒì„± ìŠ¤íƒ€ì¼ ì ì‘
3. **í™•ì¥ì„±**: ìƒˆë¡œìš´ ì†ì„± ì¶”ê°€ ìš©ì´
4. **í˜¸í™˜ì„±**: ê¸°ì¡´ Parler-TTS ëª¨ë¸ê³¼ ì™„ì „ í˜¸í™˜

### í–¥í›„ ë°œì „ ë°©í–¥
- ë” ë§ì€ ìŒì„± ì†ì„± ì§€ì› (ê°ì •, ë‚˜ì´ ë“±)
- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”
- ë‹¤êµ­ì–´ ì†ì„± ë²¡í„° í™•ì¥
- ê°œì¸í™”ëœ í™”ì ì ì‘ ì‹œìŠ¤í…œ

---

**ì´ í”„ë¡œì íŠ¸ëŠ” TTS ë¶„ì•¼ì—ì„œ íš¨ìœ¨ì„±ê³¼ ì œì–´ì„±ì„ ë™ì‹œì— ë‹¬ì„±í•œ í˜ì‹ ì ì¸ ì ‘ê·¼ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.**