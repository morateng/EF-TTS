#!/usr/bin/env python3

"""
현재 Parler-TTS 훈련 시 Loss 구조 분석
"""

def explain_current_loss_structure():
    """현재 훈련 시 사용되는 loss 구조를 설명합니다."""
    
    print("🔥 PARLER-TTS 훈련 시 LOSS 구조")
    print("=" * 60)
    
    print("\n📊 1. 메인 LOSS: CODEBOOK RECONSTRUCTION LOSS")
    print("-" * 50)
    print("위치: ParlerTTSForCausalLM.forward() 메소드")
    print("목적: 디코더가 정확한 오디오 코드북 토큰을 예측하도록 훈련")
    print()
    print("구조:")
    print("  → 총 9개 코드북 (각각 다른 주파수 대역 담당)")
    print("  → 각 코드북마다 독립적인 Cross-Entropy Loss 계산")
    print("  → 최종 loss = (코드북1 loss + ... + 코드북9 loss) / 9")
    print()
    print("수식:")
    print("  loss = 0")
    print("  for codebook in range(9):")
    print("      codebook_logits = 모델출력[codebook]")
    print("      codebook_labels = 정답토큰[codebook] ") 
    print("      codebook_loss = CrossEntropyLoss(codebook_logits, codebook_labels)")
    print("      loss += codebook_loss")
    print("  loss = loss / 9  # 평균")
    print()
    
    print("🎯 2. LABEL 처리")
    print("-" * 50)
    print("Label shape: (batch_size, seq_len, num_codebooks)")
    print("처리:")
    print("  → BOS 토큰 마스킹: labels.masked_fill(labels == BOS, -100)")
    print("  → EOS 토큰 처리: EOS가 아닌 위치만 loss 계산")
    print("  → Mask 적용: 유효한 토큰 위치에서만 loss 계산")
    print()
    
    print("⚡ 3. 벡터 기반 훈련 시 추가 LOSS (구현됨)")
    print("-" * 50)
    print("위치: ParlerTTSForConditionalGeneration.forward() 메소드")
    print("조건: use_precomputed_vectors=True이고 PEFT 모듈이 활성화된 경우")
    print()
    print("총 Loss = Main Loss + VAE Loss + Orthogonality Loss")
    print()
    print("📈 3.1 VAE Loss (Attribute 토큰용)")
    print("  목적: 각 attribute 벡터의 평균/분산 학습")
    print("  적용: female, American, quickly, medium, clean 등")
    print("  수식: KL_divergence(learned_dist, standard_normal)")
    print("  가중치: 0.1 (설정 가능)")
    print()
    print("📈 3.2 Orthogonality Loss")
    print("  목적: 서로 다른 enhanced 벡터들이 구별되도록 강제")
    print("  수식: ||Enhanced_Vectors @ Enhanced_Vectors.T - I||²")
    print("  가중치: 0.01 (설정 가능)")
    print()
    print("📈 3.3 LoRA Loss")
    print("  목적: Non-attribute 토큰 (a, voice, with 등) 적응")
    print("  방식: Main reconstruction loss에 자동으로 포함됨")
    print()
    
    print("🔄 4. LOSS 통합 과정")
    print("-" * 50)
    print("1. 디코더에서 codebook reconstruction loss 계산")
    print("2. PEFT 모듈이 있으면 VAE/orthogonality loss 계산 후 임시 저장")
    print("3. 메인 모델에서 모든 loss를 가중합하여 최종 loss 생성")
    print()
    print("코드 흐름:")
    print("  total_loss = decoder_outputs.loss  # Main reconstruction loss")
    print("  if hasattr(self, '_peft_vae_loss'):")
    print("      total_loss += 0.1 * self._peft_vae_loss")
    print("      total_loss += 0.01 * self._peft_orthogonality_loss")
    print()
    
    print("💡 5. 각 LOSS의 역할")
    print("-" * 50)
    print("🎵 Reconstruction Loss:")
    print("  → 정확한 오디오 토큰 생성 (음성 품질)")
    print("  → 9개 코드북의 균형잡힌 학습")
    print()
    print("🎨 VAE Loss:")
    print("  → Attribute 벡터의 의미론적 일관성")
    print("  → 'female'은 항상 비슷한 분포에서 샘플링")
    print("  → 과적합 방지 (regularization)")
    print()
    print("📏 Orthogonality Loss:")  
    print("  → 서로 다른 속성들이 독립적으로 학습")
    print("  → 'female'과 'American'이 서로 다른 벡터 공간 점유")
    print("  → 속성간 간섭 최소화")
    print()
    print("🔧 LoRA Loss:")
    print("  → 문법적 토큰들의 효율적 적응")
    print("  → 기존 모델 가중치 보존하면서 스타일 적응")
    print()
    
    print("📊 6. 실제 훈련 시 LOSS 값 예상")
    print("-" * 50)
    print("초기 훈련:")
    print("  → Reconstruction: ~8-10 (9개 코드북 × 1.0~1.2)")
    print("  → VAE: ~1-2 (KL divergence)")
    print("  → Orthogonality: ~0.1-0.5 (벡터간 유사도)")
    print("  → Total: ~8.2-10.5")
    print()
    print("수렴 후:")
    print("  → Reconstruction: ~2-4")
    print("  → VAE: ~0.1-0.3")
    print("  → Orthogonality: ~0.01-0.05")
    print("  → Total: ~2.1-4.3")
    print()
    
    print("⚙️  7. 하이퍼파라미터 튜닝 가이드")
    print("-" * 50)
    print("VAE Loss Weight (현재: 0.1):")
    print("  → 너무 높으면: 스타일 다양성 감소")
    print("  → 너무 낮으면: 과적합, 불안정한 생성")
    print("  → 권장: 0.05-0.2")
    print()
    print("Orthogonality Loss Weight (현재: 0.01):")
    print("  → 너무 높으면: 학습 불안정, 수렴 어려움")
    print("  → 너무 낮으면: 속성간 간섭")
    print("  → 권장: 0.005-0.02")
    print()
    
    print("🎯 8. 모니터링해야 할 지표들")
    print("-" * 50)
    print("훈련 중:")
    print("  ✅ Total Loss: 지속적으로 감소")
    print("  ✅ Reconstruction Loss: 메인 성능 지표")
    print("  ✅ VAE Loss: 너무 빠르게 0으로 가면 안됨")
    print("  ✅ Orthogonality Loss: 서서히 감소")
    print("  ✅ Per-codebook Loss: 9개가 비슷하게 감소")
    print()
    print("검증:")
    print("  ✅ 음성 품질 (MOS, 주관적 평가)")
    print("  ✅ 스타일 정확도 (원하는 attribute 반영도)")
    print("  ✅ 스타일 일관성 (같은 caption → 같은 스타일)")
    print("  ✅ 속성 독립성 (한 속성 변경 시 다른 속성 유지)")


if __name__ == "__main__":
    explain_current_loss_structure()