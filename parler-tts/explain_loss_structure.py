#!/usr/bin/env python3

"""
í˜„ì¬ Parler-TTS í›ˆë ¨ ì‹œ Loss êµ¬ì¡° ë¶„ì„
"""

def explain_current_loss_structure():
    """í˜„ì¬ í›ˆë ¨ ì‹œ ì‚¬ìš©ë˜ëŠ” loss êµ¬ì¡°ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤."""
    
    print("ğŸ”¥ PARLER-TTS í›ˆë ¨ ì‹œ LOSS êµ¬ì¡°")
    print("=" * 60)
    
    print("\nğŸ“Š 1. ë©”ì¸ LOSS: CODEBOOK RECONSTRUCTION LOSS")
    print("-" * 50)
    print("ìœ„ì¹˜: ParlerTTSForCausalLM.forward() ë©”ì†Œë“œ")
    print("ëª©ì : ë””ì½”ë”ê°€ ì •í™•í•œ ì˜¤ë””ì˜¤ ì½”ë“œë¶ í† í°ì„ ì˜ˆì¸¡í•˜ë„ë¡ í›ˆë ¨")
    print()
    print("êµ¬ì¡°:")
    print("  â†’ ì´ 9ê°œ ì½”ë“œë¶ (ê°ê° ë‹¤ë¥¸ ì£¼íŒŒìˆ˜ ëŒ€ì—­ ë‹´ë‹¹)")
    print("  â†’ ê° ì½”ë“œë¶ë§ˆë‹¤ ë…ë¦½ì ì¸ Cross-Entropy Loss ê³„ì‚°")
    print("  â†’ ìµœì¢… loss = (ì½”ë“œë¶1 loss + ... + ì½”ë“œë¶9 loss) / 9")
    print()
    print("ìˆ˜ì‹:")
    print("  loss = 0")
    print("  for codebook in range(9):")
    print("      codebook_logits = ëª¨ë¸ì¶œë ¥[codebook]")
    print("      codebook_labels = ì •ë‹µí† í°[codebook] ") 
    print("      codebook_loss = CrossEntropyLoss(codebook_logits, codebook_labels)")
    print("      loss += codebook_loss")
    print("  loss = loss / 9  # í‰ê· ")
    print()
    
    print("ğŸ¯ 2. LABEL ì²˜ë¦¬")
    print("-" * 50)
    print("Label shape: (batch_size, seq_len, num_codebooks)")
    print("ì²˜ë¦¬:")
    print("  â†’ BOS í† í° ë§ˆìŠ¤í‚¹: labels.masked_fill(labels == BOS, -100)")
    print("  â†’ EOS í† í° ì²˜ë¦¬: EOSê°€ ì•„ë‹Œ ìœ„ì¹˜ë§Œ loss ê³„ì‚°")
    print("  â†’ Mask ì ìš©: ìœ íš¨í•œ í† í° ìœ„ì¹˜ì—ì„œë§Œ loss ê³„ì‚°")
    print()
    
    print("âš¡ 3. ë²¡í„° ê¸°ë°˜ í›ˆë ¨ ì‹œ ì¶”ê°€ LOSS (êµ¬í˜„ë¨)")
    print("-" * 50)
    print("ìœ„ì¹˜: ParlerTTSForConditionalGeneration.forward() ë©”ì†Œë“œ")
    print("ì¡°ê±´: use_precomputed_vectors=Trueì´ê³  PEFT ëª¨ë“ˆì´ í™œì„±í™”ëœ ê²½ìš°")
    print()
    print("ì´ Loss = Main Loss + VAE Loss + Orthogonality Loss")
    print()
    print("ğŸ“ˆ 3.1 VAE Loss (Attribute í† í°ìš©)")
    print("  ëª©ì : ê° attribute ë²¡í„°ì˜ í‰ê· /ë¶„ì‚° í•™ìŠµ")
    print("  ì ìš©: female, American, quickly, medium, clean ë“±")
    print("  ìˆ˜ì‹: KL_divergence(learned_dist, standard_normal)")
    print("  ê°€ì¤‘ì¹˜: 0.1 (ì„¤ì • ê°€ëŠ¥)")
    print()
    print("ğŸ“ˆ 3.2 Orthogonality Loss")
    print("  ëª©ì : ì„œë¡œ ë‹¤ë¥¸ enhanced ë²¡í„°ë“¤ì´ êµ¬ë³„ë˜ë„ë¡ ê°•ì œ")
    print("  ìˆ˜ì‹: ||Enhanced_Vectors @ Enhanced_Vectors.T - I||Â²")
    print("  ê°€ì¤‘ì¹˜: 0.01 (ì„¤ì • ê°€ëŠ¥)")
    print()
    print("ğŸ“ˆ 3.3 LoRA Loss")
    print("  ëª©ì : Non-attribute í† í° (a, voice, with ë“±) ì ì‘")
    print("  ë°©ì‹: Main reconstruction lossì— ìë™ìœ¼ë¡œ í¬í•¨ë¨")
    print()
    
    print("ğŸ”„ 4. LOSS í†µí•© ê³¼ì •")
    print("-" * 50)
    print("1. ë””ì½”ë”ì—ì„œ codebook reconstruction loss ê³„ì‚°")
    print("2. PEFT ëª¨ë“ˆì´ ìˆìœ¼ë©´ VAE/orthogonality loss ê³„ì‚° í›„ ì„ì‹œ ì €ì¥")
    print("3. ë©”ì¸ ëª¨ë¸ì—ì„œ ëª¨ë“  lossë¥¼ ê°€ì¤‘í•©í•˜ì—¬ ìµœì¢… loss ìƒì„±")
    print()
    print("ì½”ë“œ íë¦„:")
    print("  total_loss = decoder_outputs.loss  # Main reconstruction loss")
    print("  if hasattr(self, '_peft_vae_loss'):")
    print("      total_loss += 0.1 * self._peft_vae_loss")
    print("      total_loss += 0.01 * self._peft_orthogonality_loss")
    print()
    
    print("ğŸ’¡ 5. ê° LOSSì˜ ì—­í• ")
    print("-" * 50)
    print("ğŸµ Reconstruction Loss:")
    print("  â†’ ì •í™•í•œ ì˜¤ë””ì˜¤ í† í° ìƒì„± (ìŒì„± í’ˆì§ˆ)")
    print("  â†’ 9ê°œ ì½”ë“œë¶ì˜ ê· í˜•ì¡íŒ í•™ìŠµ")
    print()
    print("ğŸ¨ VAE Loss:")
    print("  â†’ Attribute ë²¡í„°ì˜ ì˜ë¯¸ë¡ ì  ì¼ê´€ì„±")
    print("  â†’ 'female'ì€ í•­ìƒ ë¹„ìŠ·í•œ ë¶„í¬ì—ì„œ ìƒ˜í”Œë§")
    print("  â†’ ê³¼ì í•© ë°©ì§€ (regularization)")
    print()
    print("ğŸ“ Orthogonality Loss:")  
    print("  â†’ ì„œë¡œ ë‹¤ë¥¸ ì†ì„±ë“¤ì´ ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµ")
    print("  â†’ 'female'ê³¼ 'American'ì´ ì„œë¡œ ë‹¤ë¥¸ ë²¡í„° ê³µê°„ ì ìœ ")
    print("  â†’ ì†ì„±ê°„ ê°„ì„­ ìµœì†Œí™”")
    print()
    print("ğŸ”§ LoRA Loss:")
    print("  â†’ ë¬¸ë²•ì  í† í°ë“¤ì˜ íš¨ìœ¨ì  ì ì‘")
    print("  â†’ ê¸°ì¡´ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë³´ì¡´í•˜ë©´ì„œ ìŠ¤íƒ€ì¼ ì ì‘")
    print()
    
    print("ğŸ“Š 6. ì‹¤ì œ í›ˆë ¨ ì‹œ LOSS ê°’ ì˜ˆìƒ")
    print("-" * 50)
    print("ì´ˆê¸° í›ˆë ¨:")
    print("  â†’ Reconstruction: ~8-10 (9ê°œ ì½”ë“œë¶ Ã— 1.0~1.2)")
    print("  â†’ VAE: ~1-2 (KL divergence)")
    print("  â†’ Orthogonality: ~0.1-0.5 (ë²¡í„°ê°„ ìœ ì‚¬ë„)")
    print("  â†’ Total: ~8.2-10.5")
    print()
    print("ìˆ˜ë ´ í›„:")
    print("  â†’ Reconstruction: ~2-4")
    print("  â†’ VAE: ~0.1-0.3")
    print("  â†’ Orthogonality: ~0.01-0.05")
    print("  â†’ Total: ~2.1-4.3")
    print()
    
    print("âš™ï¸  7. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê°€ì´ë“œ")
    print("-" * 50)
    print("VAE Loss Weight (í˜„ì¬: 0.1):")
    print("  â†’ ë„ˆë¬´ ë†’ìœ¼ë©´: ìŠ¤íƒ€ì¼ ë‹¤ì–‘ì„± ê°ì†Œ")
    print("  â†’ ë„ˆë¬´ ë‚®ìœ¼ë©´: ê³¼ì í•©, ë¶ˆì•ˆì •í•œ ìƒì„±")
    print("  â†’ ê¶Œì¥: 0.05-0.2")
    print()
    print("Orthogonality Loss Weight (í˜„ì¬: 0.01):")
    print("  â†’ ë„ˆë¬´ ë†’ìœ¼ë©´: í•™ìŠµ ë¶ˆì•ˆì •, ìˆ˜ë ´ ì–´ë ¤ì›€")
    print("  â†’ ë„ˆë¬´ ë‚®ìœ¼ë©´: ì†ì„±ê°„ ê°„ì„­")
    print("  â†’ ê¶Œì¥: 0.005-0.02")
    print()
    
    print("ğŸ¯ 8. ëª¨ë‹ˆí„°ë§í•´ì•¼ í•  ì§€í‘œë“¤")
    print("-" * 50)
    print("í›ˆë ¨ ì¤‘:")
    print("  âœ… Total Loss: ì§€ì†ì ìœ¼ë¡œ ê°ì†Œ")
    print("  âœ… Reconstruction Loss: ë©”ì¸ ì„±ëŠ¥ ì§€í‘œ")
    print("  âœ… VAE Loss: ë„ˆë¬´ ë¹ ë¥´ê²Œ 0ìœ¼ë¡œ ê°€ë©´ ì•ˆë¨")
    print("  âœ… Orthogonality Loss: ì„œì„œíˆ ê°ì†Œ")
    print("  âœ… Per-codebook Loss: 9ê°œê°€ ë¹„ìŠ·í•˜ê²Œ ê°ì†Œ")
    print()
    print("ê²€ì¦:")
    print("  âœ… ìŒì„± í’ˆì§ˆ (MOS, ì£¼ê´€ì  í‰ê°€)")
    print("  âœ… ìŠ¤íƒ€ì¼ ì •í™•ë„ (ì›í•˜ëŠ” attribute ë°˜ì˜ë„)")
    print("  âœ… ìŠ¤íƒ€ì¼ ì¼ê´€ì„± (ê°™ì€ caption â†’ ê°™ì€ ìŠ¤íƒ€ì¼)")
    print("  âœ… ì†ì„± ë…ë¦½ì„± (í•œ ì†ì„± ë³€ê²½ ì‹œ ë‹¤ë¥¸ ì†ì„± ìœ ì§€)")


if __name__ == "__main__":
    explain_current_loss_structure()