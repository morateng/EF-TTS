#!/usr/bin/env python3

import torch
from parler_tts import ParlerTTSForConditionalGeneration
from parler_tts.vector_utils import VectorLoader
from parler_tts.peft_modules import PrecomputedVectorPEFT
from transformers import AutoTokenizer
import soundfile as sf

def load_trained_peft_model(peft_checkpoint_path):
    """í•™ìŠµëœ PEFT ëª¨ë“ˆì„ í¬í•¨í•œ ëª¨ë¸ ë¡œë“œ"""
    
    # 1ë‹¨ê³„: ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    model = ParlerTTSForConditionalGeneration.from_pretrained("parler-tts/parler-tts-mini-v1").to(device)
    tokenizer = AutoTokenizer.from_pretrained("parler-tts/parler-tts-mini-v1")
    vector_loader = VectorLoader("/home/user/Code/EF-TTS/parler-tts")
    
    # 2ë‹¨ê³„: PEFT ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    if torch.cuda.is_available():
        checkpoint = torch.load(peft_checkpoint_path)
    else:
        checkpoint = torch.load(peft_checkpoint_path, map_location='cpu')
    
    print("ì²´í¬í¬ì¸íŠ¸ ë‚´ìš©:")
    for key in checkpoint.keys():
        print(f"  - {key}")
    
    # 3ë‹¨ê³„: ëª¨ë¸ ì„¤ì • ì—…ë°ì´íŠ¸
    model.config.use_precomputed_vectors = True
    model.config.precomputed_vector_dim = 1024
    model.config.attribute_values = checkpoint['attribute_values']
    model.config.lora_rank = checkpoint['lora_rank']
    model.config.lora_alpha = checkpoint.get('lora_alpha', 16)
    model.config.vae_latent_dim = checkpoint['vae_latent_dim']
    model.config.orthogonal_reg_strength = checkpoint.get('orthogonal_reg_strength', 0.1)
    
    # 4ë‹¨ê³„: PEFT ëª¨ë“ˆ ì´ˆê¸°í™”
    model.vector_peft = PrecomputedVectorPEFT(
        vector_dim=1024,
        num_vectors=None,
        attribute_values=checkpoint['attribute_values'],
        lora_rank=checkpoint['lora_rank'],
        lora_alpha=checkpoint.get('lora_alpha', 16),
        vae_latent_dim=checkpoint['vae_latent_dim'],
        orthogonal_reg_strength=checkpoint.get('orthogonal_reg_strength', 0.1)
    ).to(device)
    
    # 5ë‹¨ê³„: í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    model.vector_peft.load_state_dict(checkpoint['peft_state_dict'])
    model.vector_peft.eval()
    
    print("âœ… í•™ìŠµëœ PEFT ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ!")
    
    return model, tokenizer, vector_loader

def test_trained_peft(peft_checkpoint_path):
    """í•™ìŠµëœ PEFTë¡œ ìŒì„± ìƒì„± í…ŒìŠ¤íŠ¸"""
    
    try:
        model, tokenizer, vector_loader = load_trained_peft_model(peft_checkpoint_path)
        
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
        test_cases = [
            {
                "description": "A female voice with American accent speaks quickly at a medium pitch and a clean quality",
                "prompt": "Hello, this is trained PEFT speaking."
            },
            {
                "description": "A male voice with British accent speaks slowly at a high pitch and a clean quality", 
                "prompt": "The trained model should now work correctly."
            }
        ]
        
        for i, test_case in enumerate(test_cases):
            description = test_case["description"]
            prompt = test_case["prompt"]
            
            print(f"\n--- í•™ìŠµëœ PEFT í…ŒìŠ¤íŠ¸ {i+1} ---")
            print(f"ìŠ¤íƒ€ì¼: {description}")
            print(f"í…ìŠ¤íŠ¸: {prompt}")
            
            # ë²¡í„° ì¤€ë¹„
            vectors, tokens, attributes = vector_loader.get_vectors_for_caption(description)
            print(f"ì†ì„±: {attributes}")
            
            # ëª¨ë¸ ì…ë ¥ ì¤€ë¹„
            device = next(model.parameters()).device
            prompt_input_ids = tokenizer(prompt, return_tensors="pt").input_ids.to(device)
            batch_vectors = vectors.unsqueeze(0).to(device)
            attention_mask = torch.ones((1, vectors.shape[0])).to(device)
            description_tokens = [tokens]
            
            # í•™ìŠµëœ PEFTë¡œ ìŒì„± ìƒì„±
            print("ğŸµ í•™ìŠµëœ PEFTë¡œ ìŒì„± ìƒì„± ì¤‘...")
            with torch.no_grad():
                generation = model.generate(
                    prompt_input_ids=prompt_input_ids,
                    precomputed_vectors=batch_vectors,
                    attention_mask=attention_mask,
                    description_tokens=description_tokens,
                    max_new_tokens=1000,
                    do_sample=True,
                    temperature=1.0
                )
            
            # ì˜¤ë””ì˜¤ ì €ì¥
            audio_arr = generation.cpu().numpy().squeeze()
            filename = f"trained_peft_generation_{i+1}.wav"
            sf.write(filename, audio_arr, model.config.sampling_rate)
            
            duration = len(audio_arr) / model.config.sampling_rate
            print(f"âœ… ì €ì¥: {filename} ({duration:.2f}ì´ˆ)")
            
    except FileNotFoundError:
        print("âŒ PEFT ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € í›ˆë ¨ì„ ì™„ë£Œí•´ì„œ PEFT ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥í•˜ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")

if __name__ == "__main__":
    # ì˜ˆì‹œ ì‚¬ìš©ë²•
    peft_checkpoint_path = "peft_checkpoint.pth"  # ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì •
    test_trained_peft(peft_checkpoint_path)